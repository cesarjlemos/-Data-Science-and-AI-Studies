---
title: "Análise exploratória e Regressão na base do rank de Felicidade por País de
  '2018' e '2019' com o R"
author: "Céasar Lemos - B.Sc Matemática"
date: "19/01/2020"
output:
  pdf_document:
    toc: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\newpage

# Introdução

Regressão é uma técnica que permite entender e inferir a relação de uma variável dependente ($y$) com outras variáveis chamadas variáveis explicativas ($x_1$, $x_2$,...$x_n$). Entendendo a relação entre estas variávies, é possível estimar e/ou prever a variável $y$ retornando o valor médio. Este termo foi criado por Francis Galton em seu experimento que mensurava a altura dos pais e seus respectivos filhos. Observando os dados coletados, Galton reparou que a estatura média das crianças nascidas de pais com uma certa altura tendia a "regredir" para a altura média da população. Esta lei foi confirmada por Karl Pearson que, com mais de mil observações coletadas, concluiu que a altura média de filhos de pais altos era menor do que a de seus genitores e os filhos de pais mais baixos era maior que seus pais. Ou seja, filhos de pais altos e de pais baixos "regrediam" igualmente para a altura média.

Uma forma comum de avaliar se uma variável pode inferir em outra é traçando um gráfico de dispersão. Nela, visualmente vemos se há alguma correlação, podemos ter noção do grau de correlação e se ela é linear ou não linear.

O objetivo deste artigo é realizar uma análise de regressão para verificar a inferência de indicadores econômicos e sociais sobre o indicador de felicidade mensurado por país em 2018 e projetar 2019.

# Pacotes e Importação dos dados

## Pacotes

Os pacotes utilizados para replicar o experimento estão listados abaixo. Caso não tenha nenhum instalado, pode usar o comando _install.packages_("nome do pacote entre aspas").

```{r, echo=T, eval=T, results='asis', fig.width=8, fig.height=4, fig.align='center', out.width="1\\linewidth", warning=FALSE, message=FALSE, size='small'}

library(readr)
library(caret)
library(forecast)
library(xtable)
library(tidyverse)
library(scales)
library(GGally)
library(gridExtra)
library(lmtest)
```

## Dados

Os dados foram coletados no site do Kaggle no seguinte link: <https://www.kaggle.com/unsdsn/world-happiness#2019.csv>

Os arquivos de 2018 e 2019 estão no formato _.csv_ e contém os seguintes dados por país:

\begin{itemize}

\item Score: índice que mede a felicidade da população
\item GDP per capita: Produto Interno Bruto (PIB) per capita
\item Social Support: Suporte social fornecido pelo governo
\item Healthy life expectancy: Expectativa de vida saudável
\item Freedom to make life choices: Liberdade de fazer escolhas para a sua vida
\item Generosity: Generosidade da população
\item Perceptions of corruption: Percepção de Corrupção no país

\end{itemize}

## Importando os dados

```{r eval=T, echo=T, fig.align='center', fig.height=4, fig.width=8, message=FALSE, warning=FALSE, out.width="1\\linewidth", results='asis', size='small'}

# Importando 2018
dt2018 <- read_csv(choose.files(), skip = 1,
                   col_names = c("rank","country","score","gdp","social_support",
                                 "life_expect","freedom_life","generosity","corruption"))

# Importando 2019
dt2019 <- read_csv(choose.files(), skip = 1,
                   col_names = c("rank","country","score","gdp","social_support",
                                 "life_expect","freedom_life","generosity","corruption"))

```

# Análise exploratória dos dados

Vamos olhar os dados de 2018. Ele será a base que fornecerá a função para projetar 2019.

```{r, echo=T, eval=T, results='markup', fig.width=8, fig.height=4, fig.align='center', out.width="1\\linewidth", warning=FALSE, message=FALSE, size='small'}

# Verificando o formato dos dados
str(dt2018[,3:9])

```

O indicador _Perceptions of corruption_ está como character(). Vamos ajustar para _double_ antes de prosseguirmos com a análise.

```{r eval=T, echo=T, fig.align='center', fig.height=4, fig.width=8, message=FALSE, warning=FALSE, out.width="1\\linewidth", results='asis', size='small'}

# Convertendo de Character para Double
options(digits = 3)
dt2018$corruption <- as.double(dt2018$corruption)

class(dt2018$corruption)

```
  
  
Agora o formato do dado de 2018 está correto. Vamos fazer isto para 2019 também.

```{r eval=T, echo=T, fig.align='center', fig.height=4, fig.width=8, message=FALSE, warning=FALSE, out.width="1\\linewidth", results='asis', size='small'}

# Convertendo de Character para Double
options(digits = 3)
dt2019$corruption <- as.double(dt2018$corruption)

class(dt2019$corruption)

```
  
    
    
Vamos dar continuidade verificando se existe miss value.

```{r eval=T, echo=T, fig.align='center', fig.height=4, fig.width=8, message=FALSE, warning=FALSE, out.width="1\\linewidth", results='asis', size='small'}

# Verificando a existência de miss value

result <- as.data.frame(sapply(dt2018, function(x) sum(is.na(x))))
colnames(result) <- c("Miss Value")
print(xtable(result))

```

Existe 1 miss value no indicador Perceptions of corruption. Como se trata de apenas uma observação, podemos usar a função _view(data2018)_ para visualizar toda a tabela e verificar a posição do miss value. No modelo de regressão podemos ignorar valores _n.a_, logo isso não será um problema. Uma técnica usada para lidar com situações assim é a interpolação.

Vamos continuar analisando os dados.

```{r eval=T, echo=T, fig.align='center', fig.height=4, fig.width=8, message=FALSE, warning=FALSE, out.width="1\\linewidth", results='asis', size='small'}
# Verificando os 10 primeiros países no rank
print(xtable(head(dt2018[,-1], 10)))

```

\newpage

```{r eval=T, echo=T, fig.align='center', fig.height=4, fig.width=8, message=FALSE, warning=FALSE, out.width="1\\linewidth", results='asis', size='small'}

# Verificando os 10 últimos países no rank
print(xtable(tail(dt2018[,-1], 10)))

```

```{r eval=T, echo=T, fig.align='center', fig.height=4, fig.width=8, message=FALSE, warning=FALSE, out.width="1\\linewidth", results='asis', size='small'}

# Verificando as principais estatísticas dos dados
print(xtable(summary(dt2018[,3:9])))

```

```{r eval=T, echo=T, fig.align='center', fig.height=4, fig.width=8, message=FALSE, warning=FALSE, out.width="1\\linewidth", results='asis', size='small'}

# Analisando o desvio padrão das variáveis

desvpad <- as.data.frame(sapply(dt2018[,3:9], function(x) sd(x, na.rm = T)))
colnames(desvpad) <- c("Desvio Padrão")
print(xtable(desvpad))

```

\newpage 
Vamos gerar os gráficos de correlação usando o pacote GGPlot2

```{r, echo=T, eval=T, results='markup', fig.width=8, fig.height=4, fig.align='center', out.width="1\\linewidth", warning=FALSE, message=FALSE, size='small'}

# Plotando as Correlações
corr1 <- ggplot(dt2018) +
  geom_point(mapping = aes(x = score, y = gdp)) +
  geom_smooth(mapping = aes(x = score, y = gdp), method = lm)

corr2 <- ggplot(dt2018) +
  geom_point(mapping = aes(x = score, y = social_support)) +
  geom_smooth(mapping = aes(x = score, y = social_support), method = lm)

corr3 <- ggplot(dt2018) +
  geom_point(mapping = aes(x = score, y = life_expect)) +
  geom_smooth(mapping = aes(x = score, y = life_expect), method = lm)

corr4 <- ggplot(dt2018) +
  geom_point(mapping = aes(x = score, y = freedom_life)) +
  geom_smooth(mapping = aes(x = score, y = freedom_life), method = lm)

corr5 <- ggplot(dt2018) +
  geom_point(mapping = aes(x = score, y = generosity)) +
  geom_smooth(mapping = aes(x = score, y = generosity), method = lm)

corr6 <- ggplot(dt2018) +
  geom_point(mapping = aes(x = score, y = corruption)) +
  geom_smooth(mapping = aes(x = score, y = corruption), method = lm)

grid.arrange(corr1, corr2, corr3, corr4, corr5, corr6, ncol=3)

```

Analisando os gráficos, é perceptível que a correlação entre o score e a generosity e corruption não ocorre de forma linear. Com isso, podemos supor que estas variáveis terão um nível de significância ($p-value$) maior que $0,05$, aceitando a hipótese nula (${\displaystyle H_{0}}$)

# Fazendo o modelo de Regressão Linear

Para rodar o modelo de Regressão Linear, basta executar o seguinte código:


```{r, echo=T, eval=T, results='markup', fig.width=8, fig.height=4, fig.align='center', out.width="1\\linewidth", warning=FALSE, message=FALSE, size='small'}

lm_model <- lm(score~., dt2018[,3:9])
summary(lm_model)

```

Conforme visto no gráfico, as variáveis _generosity_ e _corruptuon_ não apresentam significância para explicar o score a um nível de confiança aceitável, portanto, vamos otimizar esta regressão usando a função _step()_. Esta função escolhe as melhores variáveis utilizando o _Critério de Informação de Akaike (AIC)_.

```{r, echo=T, eval=T, results='markup', fig.width=8, fig.height=4, fig.align='center', out.width="1\\linewidth", warning=FALSE, message=FALSE, size='small'}

lm_model <- step(lm(score~., dt2018[,3:9]), direction = "both")
summary(lm_model)

```

Como visto na tabela acima, a função _step()_ com o argumento _both_ selecionou a variável corruption que, sem a presença da variável _generosity_, tem um nível de confiança de $90$%, conforme o teste do $p$-$value$. Todas as outras apresentam um nível de confiança maior que $95$%. Já o $R^2$ aponta que estas variáveis explicam $78,9$% do _score_.

Dando uma olhada nos resíduos da regressão, vemos que os erros não apresentam uma distribuição normal. O teste de Shapiro nos confirma isto apresentando um $p$-$value$ acima de $0.05$.

```{r, echo=T, eval=T, results='markup', fig.width=8, fig.height=4, fig.align='center', out.width="1\\linewidth", warning=FALSE, message=FALSE, size='small'}

checkresiduals(lm_model)

```

```{r, echo=T, eval=T, results='markup', fig.width=8, fig.height=4, fig.align='center', out.width="1\\linewidth", warning=FALSE, message=FALSE, size='small'}

shapiro.test(lm_model$residuals)

```

Um dos problemas comuns em regressão e que impacta bastante o modelo é a multicolinearidade. Vamos verificar a existência usando o código abaixo:

```{r, echo=T, eval=T, results='markup', fig.width=8, fig.height=4, fig.align='center', out.width="1\\linewidth", warning=FALSE, message=FALSE, size='small'}

ggpairs(dt2018[,3:9])

```

Podemos perceber uma forte correlação entre as variáveis _GDP_ e _life expect_, com um índice de $0.844$. Vamos tirar a variável _life expect_ do modelo para realizar o ajuste, pois a variável _GDP_ apresenta uma correlação maior com o _score_.

```{r, echo=T, eval=T, results='markup', fig.width=8, fig.height=4, fig.align='center', out.width="1\\linewidth", warning=FALSE, message=FALSE, size='small'}

lm_model <- lm(score~gdp+social_support+freedom_life+corruption, dt2018[,3:9])
summary(lm_model)

```

```{r, echo=T, eval=T, results='markup', fig.width=8, fig.height=4, fig.align='center', out.width="1\\linewidth", warning=FALSE, message=FALSE, size='small'}

checkresiduals(lm_model)

```

```{r, echo=T, eval=T, results='markup', fig.width=8, fig.height=4, fig.align='center', out.width="1\\linewidth", warning=FALSE, message=FALSE, size='small'}


shapiro.test(lm_model$residuals)

```

Outro problema comum nas regressões de cortes trasversais é a _heterocedasticidade_. Podemos gerar um gráfico de correlação entre os resóduos e a variável dependente do modelo e rodar o teste de Breusch-Pagan para verificar a existência deste problema:

```{r, echo=T, eval=T, results='markup', fig.width=8, fig.height=4, fig.align='center', out.width="1\\linewidth", warning=FALSE, message=FALSE, size='small'}

resid <- as.data.frame(lm_model$residuals)
colnames(resid) <- c("residual")
dtcheck <- cbind(dt2018[-20,], resid)

ggplot(dtcheck) +
  geom_point(mapping = aes(x = score, y= residual))+
  geom_smooth(mapping = aes(x = score, y= residual), method = lm)

```

```{r, echo=T, eval=T, results='markup', fig.width=8, fig.height=4, fig.align='center', out.width="1\\linewidth", warning=FALSE, message=FALSE, size='small'}

bptest(lm_model)

```

Como o _p-value_ é maior que $0,05$, temos que rejeitar a hipótese nula e assumir que este modelo apresenta heterocedasticidade, ou seja, os estimadores pelo MQO não são os melhores estimadores lineares não viesados.

Embora exista heterocedasticidade, a distribuição dos erros ocorre de forma normal (conforme demonstrado no teste de Shapiro após exclusão da variável life_expect) o que indica que o MQO ainda é o melhor estimador e que este problema provavelmente ocorre por ausência de outras variáveis que explicam o _score_.

Com o modelo ajustado em mãos, vamos utilizar os indicadores de 2019 para prever o _score_ e verificar a margem de erro.

```{r, echo=T, eval=T, results='markup', fig.width=8, fig.height=4, fig.align='center', out.width="1\\linewidth", warning=FALSE, message=FALSE, size='small'}

fcast <- forecast(lm_model, newdata = dt2019, level = 95)
accuracy(fcast$mean, dt2019$score)

```

É visível que o erro médio absoluto percentual (MAPE) e o erro médio absoluto (MAE) está relativamente alto. Pode-se dizer que o modelo necessita de mais variáveis para tentar explicar o _score_ de felicidade.

```{r eval=T, echo=T, fig.align='center', fig.height=4, fig.width=8, message=FALSE, warning=FALSE, out.width="1\\linewidth", results='asis', size='small'}

dtfcast <- as.data.frame(cbind(dt2019$country,
                               round(fcast$mean,3),dt2019$score))
colnames(dtfcast) <- c("country","forecast_score","real_score")

print(xtable(head(dtfcast,10)))
```

# Conclusão

Os dados obtidos do rank de felicidade por países nos fornece variáveis que explicam de fato o _score_. Entretanto, foi identificado alguns problemas que necessitaram ajustes, como multicolinearidade entre variáveis explicativas e a ausência de correlação entre a generosidade e o score. O modelo ajustado de regressão foi capaz de explicar em $77,7$% o _score_, porém, não foi suficiente para fazer predições com alta acurácia. O modelo necessita de mais informações para predizer com um nível maior de assertividade.